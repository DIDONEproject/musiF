{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99af7aa1",
   "metadata": {},
   "source": [
    "# Getting started `musif`\n",
    "\n",
    "`musif` is a Python library to analyze music scores. It is a tool to massively extract features from MusicXML and MuseScore files.\n",
    "\n",
    "`musif` was born in the context of the [ERC Project \"DIDONE\"](https://didone.eu/) and, consequently,\n",
    "it is specialized in 18th-century Italian opera arias. However, it is also prepared to work with other repertoires.\n",
    "\n",
    "This tutorial is an introduction for people who are not experts in programming. If you are already an expert, just skip to the [Data Section](#data) and then go to the [Advanced Tutorial](https://musif.didone.eu/Tutorial%20poprock.html).\n",
    "\n",
    "\n",
    "## Installation\n",
    "\n",
    "First, you should install [`Python`](https://www.python.org/downloads/) > 3.10. An easy way to do this is by using [`Anaconda`](https://www.anaconda.com/products/distribution), especially if you are not used to commandline interface.A\n",
    "Once you have installed `anaconda`:\n",
    "1. Launch the `anaconda-navigator`\n",
    "2. [Create an environment](https://docs.anaconda.com/navigator/getting-started/#managing-environments) selecting python version >= 3.10\n",
    "3. Switch to the newly created environment by clicking on its name\n",
    "\n",
    "\n",
    "To install `musif`:\n",
    "1. [Download](https://raw.githubusercontent.com/DIDONEproject/musif/main/docs/source/Tutorial.ipynb) this notebook.\n",
    "2. Start `jupyter` in your Anaconda environment.\n",
    "3. Open this tutorial.\n",
    "4. Run the following cell by clicking on it and pressing Ctrl+Enter."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91eac574",
   "metadata": {},
   "source": [
    "Here, the `!` is a special command that executes commands in the terminal. After having run it, you may need to restart the notebook (click the circular arrow ↻ in the top bar, near the icons ▶ and ⏹)\n",
    "\n",
    "To run this tutorial:\n",
    "1. In the `Home` tab of the `anaconda-navigator`, select \"All applications\" and the newly created environment in the options at the top.\n",
    "2. Click on `Install`, near to the `Jupyter` icon\n",
    "3. Once installed, click on `launch` near the `notebook` icon; a web interface will open in the browser\n",
    "4. [Download](https://raw.githubusercontent.com/DIDONEproject/musif/main/docs/source/Tutorial.ipynb) by clicking iwth right mouse button and selecting \"save as...\"\n",
    "5. Navigate to the downloaded file from the web interface and open it\n",
    "6. Run the following cell by clicking on it and pressing Ctrl+Enter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7710973",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install musif"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01cd214c",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "If you are new to Python, we suggest you to read an introductory tutorial for it, for instance, [this one](https://www.w3schools.com/python/default.asp). \n",
    "\n",
    "In the following, we will introduce some technical terminology that may be useful to you to understand technical documentation while working with `musif`:\n",
    "\n",
    "* A _function_ is a way to represent code that is convenient for humans. You can think of functions as mathematical functions, with some input and some output. However, some programming languages call them _procedures_; this is not the case with Python, but this name allows grasping what functions are, after all: successions of commands that the computer has to execute.\n",
    "\n",
    "* An _object_ is a computational way to represent information _and_ code in the memory of computers; you can think of objects as real concepts of the real world: objects have properties (in Python named _fields_) and functionalities (named _methods_). For instance, an object could be a vehicle, which has some properties (length, maximum speed, number of wheels) and some functionalities (accelerate, decelerate, stop). Objects can also have specializations (named _children_): in our example, a _child_ of vehicle could be the car and another _child_ could be the bike: they have different properties and apply the functionalities in a different way. Both the vehicle, the car, and the bike may have instances: the car that you use everyday to go to work is different from your friend's even if they have the same exact properties, because they are two different concrete objects. Technically, those two cars are two _instances_ of the same _class_. To create an instance, you have to call a function, generically named _constructor_, which takes as arguments the class and the other properties. This function will return the instance. To use `musif`, you don't need to know a lot about objects, but while you search the web it is good to have a little of knowledge.\n",
    "\n",
    "* A _DataFrame_ is another way to represent information for computers. They are designed to be extremely efficient, even if sometimes some aspects of the information can get lost. They are mainly used for data science problems. You can think of a _DataFrame_ as a table, with rows and columns. Usually, rows are _instances_ while columns are _properties_. In data science, these words often become _samples_ and _features_/_variables_. A typical operation is to select only certain columns (properties) or only certain rows (instances) to select subset of the data or to modify the data itself.\n",
    "\n",
    "* Don't be scared to use web search engines such as Google: searching the web in a proper way is one of the most important skills a programmer has!\n",
    "\n",
    "### Main objects\n",
    "\n",
    "When using `musif`, you will usually interface with two objects:\n",
    "1. [`FeaturesExtractor()`](API/musif.extract.html#musif.extract.extract.FeaturesExtractor), which reads music scores and computes a DataFrame containing all the extracted features. In the simplest case, each row represents a music score, while each column represents a feature.\n",
    "2. [`DataProcessor()`](API/musif.process.html#musif.process.processor.DataProcessor), which takes the DataFrame with all the features in it and post-processes it to clean, improve, and possibly modify some of the features.\n",
    "\n",
    "These two objects take as input two different configurations that modify their behavior. In other words, the constructors of `FeaturesExtractor` and `DataProcessor` can accept a wide range of arguments.\n",
    "\n",
    "But let's proceed step by step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8119d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"data\")\n",
    "dataset_path = \"dataset.zip\"\n",
    "urllib.request.urlretrieve(\"https://zenodo.org/record/4027957/files/AnatomyComposerAttributionMIDIFilesAndFeatureData_1_0.zip?download=1\", dataset_path)\n",
    "with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(data_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cab6f329",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Let's create a configuration for our experiment. Configurations can be expressed using a `yaml` file or with key-value arguments. `yaml` files are designed for complex projects, while key-value arguments are perfect for simple situations like this.\n",
    "\n",
    "Key-value arguments are something similar to a dictionary: There is a _key_ which must be unique in the dictionary; each _key_ is associated with a _value_, which can instead be repeated. Python can retrieve a value using its key in  a very efficient way!\n",
    "\n",
    "First, we'll need to import the class that describes how a configuration is:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7c511bb",
   "metadata": {},
   "source": [
    "Now, we can call its constructor to obtain a configuration object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe4511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "config = ExtractConfiguration(\n",
    "    None,\n",
    "    musescore_dir=\"data\",\n",
    "    basic_modules=[\"scoring\"],\n",
    "    features=[\"core\", \"ambitus\", \"interval\", \"tempo\", \n",
    "              \"density\", \"texture\", \"lyrics\", \"scale\", \n",
    "              \"key\", \"dynamics\", \"rhytm\"],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64a59048",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "\n",
    "Now that we have our configuration, we pass it to the function that creates `FeaturesExtraction` objects. This function is exactly named `FeaturesExtraction`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b900810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from musif.extract.extract import FeaturesExtractor\n",
    "\n",
    "extractor = FeaturesExtractor(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d423b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = FeaturesExtractor(\n",
    "    None,\n",
    "    musescore_dir=\"data\",\n",
    "    basic_modules=[\"scoring\"],\n",
    "    features=[\"core\", \"ambitus\", \"melody\", \"tempo\", \n",
    "              \"density\", \"texture\", \"lyrics\", \"scale\", \n",
    "              \"key\", \"dynamics\", \"rhythm\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "343373ac",
   "metadata": {},
   "source": [
    "Before starting the extraction, we also need to tell MuseScore the type of files it should look for. In this case, we want it to look for files with extension `'.mid'`. By default, it would look for `.mscx` files, so we need to change it:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "756f12ba",
   "metadata": {},
   "source": [
    "Now, we can start the extraction using the method `extract`. It will return a `DataFrame`:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b29fedc",
   "metadata": {},
   "source": [
    "## Post-processing\n",
    "\n",
    "Most of the features we have computed actually need some post-processing, for instance to replace `NaN` with 0, merge columns, or remove features created while computing other features.\n",
    "\n",
    "For this, we need a further step. In the next cell we will:\n",
    "1. Instantiate a `DataProcessor` object using:\n",
    "    * the generated DataFrame\n",
    "    * the default configuration (i.e. `None` in place of the yaml file/configuration object)\n",
    "2. Call the method `process()` of that object to start the post-processing of the features\n",
    "3. We retrieve the post-processed data from the field `data`\n",
    "4. We print the size of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c706fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from musif.process.processor import DataProcessor\n",
    "\n",
    "processed_df = DataProcessor(df, None).process().data\n",
    "\n",
    "# with `.shape` you can see the number of rows and columns of the dataframe\n",
    "processed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df5c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.dropna(axis=1, inplace=True)\n",
    "processed_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7cc69508",
   "metadata": {},
   "source": [
    "The dataset was not very well formatted and this is the reason why only a few features remain.\n",
    "\n",
    "## Statistical processing\n",
    "\n",
    "Let's try to classify the features. We will setup a feature-learning approach with an autoencoder architecture.\n",
    "\n",
    "For this, we will use `sklearn` and its Multilayer Perceptron, so you will need to [install](https://docs.anaconda.com/navigator/getting-started/#managing-packages) `scikit-learn` and `seaborn` packages in your anaconda environment.\n",
    "\n",
    "In the next cell, the topic becomes a little more technical, but it's just an example to show that you can use this DataFrame for statistical analysis. We will first remove redundant information (the `FileName` and the `Id` columns that were automatically assigned by the `FeatureExtractor`). \n",
    "\n",
    "Then, we will create a model which:\n",
    "1. Assigns a number to each feature that has strings as values (`OrdinalEncoder`).\n",
    "2. Standardizes the features to get comparable values.\n",
    "3. Trains a simple feed-forward fully connected autoencoder with ReLU activations and LBGFS optimizer.\n",
    "\n",
    "The objective is to learn a 2D space where the 396 extracted features can be represented without loosing information."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f75abded",
   "metadata": {},
   "source": [
    "Now, we will attach a method `transform` to the MLPClassifier which returns the activations at the inner layer with 2 outputs, that we interpret as latent features. To compare the features, we will scale them in [0, 1].\n",
    "\n",
    "Then, we plot the music scores according to the learned feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278cdf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mlpclassifier = model['mlpregressor']\n",
    "\n",
    "def mytransform_method(X):\n",
    "    activations = [None for _ in range(mlpclassifier.n_layers_)]\n",
    "    activations[0] = X\n",
    "    X = mlpclassifier._forward_pass(activations)[-6]\n",
    "    return MinMaxScaler().fit_transform(X)\n",
    "\n",
    "mlpclassifier.transform = mytransform_method\n",
    "\n",
    "learned_features = model.transform(processed_df)\n",
    "\n",
    "learned_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e64c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_pipeline = make_pipeline(\n",
    "    preprocessor, PCA(2), MinMaxScaler()\n",
    ")\n",
    "data_pca = pca_pipeline.fit_transform(processed_df)\n",
    "ax = seaborn.scatterplot(x=data_pca[:, 0], y=data_pca[:, 1])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3fac8f976d2c4ee2bc715215bb95954c479b3e9d5186e3f6df5c366b6270a4af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
